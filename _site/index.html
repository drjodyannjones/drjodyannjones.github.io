<!DOCTYPE html>
<html lang="en">
<title>Home | Dr. Jody-Ann S. Jones</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="author" content="Dr. Jody-Ann S. Jones">
<meta name="generator" content="Jekyll v4.2.2">
<link rel="canonical" href="http://localhost:4000/">

<link rel="stylesheet" href="/assets/css/frame.css">

<link rel="alternate" href="/feed.xml" type="application/atom+xml" title="Dr. Jody-Ann S. Jones">







<header>
  <a href="/" class="title">Dr. Jody-Ann S. Jones</a>
  <nav><a href="/" class="selected">Home</a><a href="/about/" >About</a></nav>

</header>


  
  <article>
    <header>
  <h1><a href="/end-to-end-image-classifier/">End-to-End Image Classification App</a></h1><time datetime="2024-04-22T00:00:00+02:00">April 22, 2024</time>
</header>

    <p>The <strong>End-to-End Cancer Classification App</strong> utilizes TensorFlow to train a binary classification model on a dataset of chest CT images. Images are categorized in two classes: adenocarcinoma and normal cases. Using a pre-trained, base model, VGG16, I built a convolutional neural network (CNN) model that assigns images to either class. The model is accessible through a frontend using the Gradio framework, which features an intuitive, user-friendly interface allowing for straightforward interactions, such as image uploads or direct pasting from the web or local storage. Detailed information about this project is available on my <a href="https://github.com/drjodyannjones/End-to-End-Cancer-Classification-Project" target="\_blank">GitHub repository</a>.</p>

<h3 id="project-overview">Project Overview</h3>

<p>This project was conceived to harness the power of deep learning algorithms for the precise classification of medical imaging, thereby enhancing diagnostic accuracy. One significant application of this model is to support healthcare professionals, such as radiologists, by offering faster and more precise assessments critical during the treatment planning phase.</p>

<p>Beyond its initial application in aiding radiologists, the potential of the project extends to several other fields. For instance, it could be adapted for use in pathology to enhance the detection and analysis of histopathological slides, significantly speeding up the process of diagnosing diseases at the cellular level. Additionally, the model could be utilized in emergency medicine to quickly analyze images in critical care settings, facilitating faster decision-making where time is of the essence. Furthermore, its adaptability means it could also support research in epidemiology by providing insights into disease patterns and prevalence through large-scale image analysis, thereby contributing to public health strategies and preventive medicine. This breadth of applications highlights the versatility and impact of advanced machine learning models in various aspects of healthcare and research.</p>

<p>You may the view the app’s screenshot by clicking the following link:
<a href="https://i.imgur.com/bnbgOpb.png">Screenshot: Chest CT Scan Classifier</a></p>

<h3 id="technologies-employed">Technologies Employed</h3>

<ul>
  <li><strong>Python:</strong> I used Python for developing machine learning algorithms and for data manipulation.</li>
  <li><strong>TensorFlow and Keras:</strong> These tools were essential in building and training the deep learning models.</li>
  <li><strong>OpenCV:</strong> This library was utilized for processing images, preparing them for the training process.</li>
  <li><strong>Jupyter Notebook:</strong> I documented the development and testing phases using Jupyter Notebook, which facilitated a clear presentation of the methodologies and results.</li>
  <li><strong>Gradio:</strong> I used Gradio to create the frontend framework.</li>
  <li><strong>MLFlow</strong> I used MLFlow for experiment tracking.</li>
  <li><strong>DVC</strong> I used DVC for data version tracking and control.</li>
</ul>

<h2 id="getting-started">Getting Started</h2>

<h3 id="installation">Installation</h3>

<p>Interested parties can replicate or review the project by following these steps:</p>

<p>Step 1. Clone the repository by typing the following in your terminal:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/drjodyannjones/End-to-End-Cancer-Classification-Project.git
</code></pre></div></div>

<p>Step 2. Create a virtual environment.</p>

<p>Step 3. Activate the newly created virtual environment.</p>

<p>Step 4. Navigate to the project directory and install necessary dependencies by typing the following in your terminal:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
</code></pre></div></div>

<p>Step 5. Run the app by typing the following in your terminal</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gradio app.py
</code></pre></div></div>

<h3 id="sample-code-snippet-predictionpy">Sample Code Snippet: prediction.py</h3>

<p>Below is a sample code snippet from the project, illustrating the loading of the trained tensorflow model and the logic used to generate predictions.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing</span> <span class="kn">import</span> <span class="n">image</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">class</span> <span class="nc">PredictionPipeline</span><span class="p">:</span>
<span class="k">def</span> <span class="err">**</span><span class="nf">init</span><span class="o">**</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="s">"artifacts"</span><span class="p">,</span> <span class="s">"training"</span><span class="p">,</span> <span class="s">"model.h5"</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">test_image</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">load_img</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
            <span class="n">test_image</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">test_image</span><span class="p">)</span>
            <span class="n">test_image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">test_image</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_image</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">prediction</span> <span class="o">=</span> <span class="s">"Normal"</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">prediction</span> <span class="o">=</span> <span class="s">"Adenocarcinoma Cancer"</span>

            <span class="k">return</span> <span class="p">[{</span><span class="s">"image"</span><span class="p">:</span> <span class="n">prediction</span><span class="p">}]</span>
        <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Error during prediction: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">[{</span><span class="s">"image"</span><span class="p">:</span> <span class="s">"Prediction error"</span><span class="p">}]</span></code></pre></figure>

<p><strong>Acknowledgements</strong></p>

<ul>
  <li>Special shoutout to <a href="https://www.youtube.com/watch?v=-NOIWzjJK-4&amp;t=17851s&amp;ab_channel=DSwithBappy">DSwithBappy</a> who inspired this project.</li>
</ul>

    <div class="more"><a href="/end-to-end-image-classifier/">read more</a></div>
  </article>

  <article>
    <header>
  <h1><a href="/real-estate-data-engineering/">Streaming Real Estate Data Engineering Application</a></h1><time datetime="2024-04-21T00:00:00+02:00">April 21, 2024</time>
</header>

    <p>In this project, I designed and implemented a real-time streaming end-to-end data engineering pipeline that captures real estate listings from <a href="https://www.zoopla.co.uk/" target="\_blank">Zoopla</a> using the <a href="https://brightdata.com/" target="\_blank">BrightData API</a>. The data flows through a Kafka cluster, a message broker, which effectively manages the movement of data from the source to the storage system (sink), in this case, Cassandra DB. Utilizing Apache Spark, the pipeline handles large-scale data processing efficiently. This setup is specifically engineered to optimize real estate market analysis, providing a robust tool for dynamic and precise market evaluation. For an in-depth look at the project, you are welcome to visit my <a href="https://github.com/drjodyannjones/RealEstateDataEngineering" target="\_blank">GitHub repository</a>.</p>

<h3 id="project-overview">Project Overview</h3>

<p>The <strong>Real Estate Data Engineering</strong> project leverages cutting-edge data processing technologies to generate actionable insights from comprehensive real estate datasets. This initiative enhances decision-making capabilities for stakeholders by providing sophisticated tools for analyzing market trends, property valuations, and investment opportunities in real-time. By integrating real-time data streaming with advanced analytical processes, this project supports a wide range of applications, including:</p>

<ul>
  <li><strong>Market Trend Analysis</strong>: Analysts can detect market shifts and emerging trends as they happen, enabling faster strategic responses.</li>
  <li><strong>Investment Decision Support</strong>: Investors gain access to up-to-date information on property values and market conditions, aiding in better investment choices.</li>
  <li><strong>Portfolio Management</strong>: Real estate companies can manage their assets more effectively by having current data at their fingertips, facilitating better operational and financial decisions.</li>
  <li><strong>Risk Management</strong>: By analyzing current and historical data trends, risks associated with investments can be better assessed and mitigated.</li>
</ul>

<p>This project exemplifies the power of integrating multiple technologies to transform raw data into a valuable strategic asset, driving forward the capabilities of real estate market analytics.</p>

<h3 id="technologies-employed">Technologies Employed</h3>

<ul>
  <li><strong>Python:</strong> Used for scripting data collection, transformation, and aggregation processes.</li>
  <li><strong>Apache Spark:</strong> Employed to efficiently manage large-scale data processing.</li>
  <li><strong>Docker:</strong> Applied to containerize the development environment to ensure consistency across different platforms.</li>
  <li><strong>Apache Kafka</strong> A cluster of Apache Kafka brokers used as the conduit to transmit data from the source to sink with low latency.</li>
  <li><strong>Brightdata API</strong> I setup a Brightdata web scraper to seamlessly web scrape real estate listings in the UK from Zoopla’s website.</li>
  <li><strong>CassandraDB</strong> A NoSQL database designed to manage large amounts of data. This is our sink</li>
  <li><strong>OpenAI</strong> This helps with the querying of property listings on Zoopla’s website.</li>
</ul>

<h2 id="getting-started">Getting Started</h2>

<h3 id="installation">Installation</h3>

<p>Step 1. Clone the repository to your local machine:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/drjodyannjones/RealEstateDataEngineering.git
</code></pre></div></div>

<p>Step 2. Building Docker Image:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker build <span class="nt">-t</span> my-custom-spark:3.5.0 <span class="nb">.</span>
</code></pre></div></div>

<p>Step 3. Start Docker Container (make sure the Docker client is up and running on your machine first!)</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker compose up <span class="nt">-d</span>
</code></pre></div></div>

<p>Step 3. Start Data Ingestion process:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python main.py
</code></pre></div></div>

<p>Step 4. Start Spark Consumer:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker <span class="nb">exec</span> <span class="nt">-it</span> realestatedataengineering-spark-master-1 spark-submit <span class="se">\</span>
    <span class="nt">--packages</span> com.datastax.spark:spark-cassandra-connector_2.12:3.4.1,org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 <span class="se">\</span>
    <span class="nb">jobs</span>/spark-consumer.py
</code></pre></div></div>

<h3 id="sample-code-snippet-spark-consumerpy">Sample Code Snippet: spark-consumer.py</h3>

<p>In this example, I showcase how Apache Spark serves as an efficient consumer by extracting data from Apache Kafka and subsequently storing it in CassandraDB:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">cassandra.cluster</span> <span class="kn">import</span> <span class="n">Cluster</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">from_json</span><span class="p">,</span> <span class="n">col</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StructType</span><span class="p">,</span> <span class="n">StructField</span><span class="p">,</span> <span class="n">StringType</span><span class="p">,</span> <span class="n">FloatType</span><span class="p">,</span> <span class="n">ArrayType</span>

<span class="c1"># Configure logging
</span>
<span class="n">logging</span><span class="p">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="p">.</span><span class="n">INFO</span><span class="p">)</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="p">.</span><span class="n">getLogger</span><span class="p">(</span><span class="o">**</span><span class="n">name</span><span class="o">**</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_cassandra_session</span><span class="p">():</span>
<span class="s">"""Retrieve or create a Cassandra session."""</span>
<span class="k">if</span> <span class="s">'cassandra_session'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">globals</span><span class="p">():</span>
<span class="n">cluster</span> <span class="o">=</span> <span class="n">Cluster</span><span class="p">([</span><span class="s">"cassandra"</span><span class="p">])</span>
<span class="nb">globals</span><span class="p">()[</span><span class="s">'cassandra_session'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cluster</span><span class="p">.</span><span class="n">connect</span><span class="p">()</span>
<span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="s">'cassandra_session'</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">setup_cassandra</span><span class="p">(</span><span class="n">session</span><span class="p">):</span>
<span class="s">"""Setup the keyspace and table in Cassandra."""</span>
<span class="n">session</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="s">"""
CREATE KEYSPACE IF NOT EXISTS property_streams
WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};
"""</span><span class="p">)</span>
<span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Keyspace created successfully!"</span><span class="p">)</span>

    <span class="n">session</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="s">"""
        CREATE TABLE IF NOT EXISTS property_streams.properties (
            price text, title text, link text, pictures list&lt;text&gt;, floor_plan text,
            address text, bedrooms text, bathrooms text, receptions text, epc_rating text,
            tenure text, time_remaining_on_lease text, service_charge text,
            council_tax_band text, ground_rent text, PRIMARY KEY (link)
        );
    """</span><span class="p">)</span>
    <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Table created successfully!"</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">insert_data</span><span class="p">(</span>\<span class="o">*</span>\<span class="o">*</span><span class="n">kwargs</span><span class="p">):</span>
<span class="s">"""Insert data into Cassandra table using a session created at the executor."""</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">get_cassandra_session</span><span class="p">()</span>
<span class="n">session</span><span class="p">.</span><span class="n">execute</span><span class="p">(</span><span class="s">"""
INSERT INTO property_streams.properties (
price, title, link, pictures, floor_plan, address, bedrooms, bathrooms,
receptions, epc_rating, tenure, time_remaining_on_lease, service_charge, council_tax_band, ground_rent
) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
"""</span><span class="p">,</span> <span class="p">(</span>
<span class="n">kwargs</span><span class="p">[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">'title'</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">'link'</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">'pictures'</span><span class="p">],</span>
<span class="n">kwargs</span><span class="p">[</span><span class="s">'floor_plan'</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">'address'</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">'bedrooms'</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">'bathrooms'</span><span class="p">],</span>
<span class="n">kwargs</span><span class="p">[</span><span class="s">'receptions'</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">'epc_rating'</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">'tenure'</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">'time_remaining_on_lease'</span><span class="p">],</span>
<span class="n">kwargs</span><span class="p">[</span><span class="s">'service_charge'</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">'council_tax_band'</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">'ground_rent'</span><span class="p">]</span>
<span class="p">))</span>
<span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Data inserted successfully!"</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">define_kafka_to_cassandra_flow</span><span class="p">(</span><span class="n">spark</span><span class="p">):</span>
<span class="s">"""Define data flow from Kafka to Cassandra using Spark."""</span>
<span class="n">schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">([</span>
<span class="n">StructField</span><span class="p">(</span><span class="s">"price"</span><span class="p">,</span> <span class="n">FloatType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
<span class="n">StructField</span><span class="p">(</span><span class="s">"title"</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
<span class="n">StructField</span><span class="p">(</span><span class="s">"link"</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
<span class="n">StructField</span><span class="p">(</span><span class="s">"pictures"</span><span class="p">,</span> <span class="n">ArrayType</span><span class="p">(</span><span class="n">StringType</span><span class="p">()),</span> <span class="bp">True</span><span class="p">),</span>
<span class="n">StructField</span><span class="p">(</span><span class="s">"floor_plan"</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
<span class="n">StructField</span><span class="p">(</span><span class="s">"address"</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
<span class="n">StructField</span><span class="p">(</span><span class="s">"bedrooms"</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
<span class="n">StructField</span><span class="p">(</span><span class="s">"bathrooms"</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
<span class="n">StructField</span><span class="p">(</span><span class="s">"receptions"</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
<span class="n">StructField</span><span class="p">(</span><span class="s">"epc_rating"</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
<span class="n">StructField</span><span class="p">(</span><span class="s">"tenure"</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
<span class="n">StructField</span><span class="p">(</span><span class="s">"time_remaining_on_lease"</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
<span class="n">StructField</span><span class="p">(</span><span class="s">"service_charge"</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
<span class="n">StructField</span><span class="p">(</span><span class="s">"council_tax_band"</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">),</span>
<span class="n">StructField</span><span class="p">(</span><span class="s">"ground_rent"</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="bp">True</span><span class="p">)</span>
<span class="p">])</span>

    <span class="n">kafka_df</span> <span class="o">=</span> <span class="p">(</span><span class="n">spark</span>
                <span class="p">.</span><span class="n">readStream</span>
                <span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="s">"kafka"</span><span class="p">)</span>
                <span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"kafka.bootstrap.servers"</span><span class="p">,</span> <span class="s">"kafka-broker:9092"</span><span class="p">)</span>
                <span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"subscribe"</span><span class="p">,</span> <span class="s">"properties"</span><span class="p">)</span>
                <span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"startingOffsets"</span><span class="p">,</span> <span class="s">"earliest"</span><span class="p">)</span>
                <span class="p">.</span><span class="n">load</span><span class="p">()</span>
                <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"CAST(value AS STRING) as value"</span><span class="p">)</span>
                <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">from_json</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s">"value"</span><span class="p">),</span> <span class="n">schema</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"data"</span><span class="p">))</span>
                <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"data.*"</span><span class="p">))</span>

    <span class="n">kafka_df</span><span class="p">.</span><span class="n">writeStream</span><span class="p">.</span><span class="n">foreachBatch</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">batch_df</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">batch_df</span><span class="p">.</span><span class="n">foreach</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">insert_data</span><span class="p">(</span><span class="o">**</span><span class="n">row</span><span class="p">.</span><span class="n">asDict</span><span class="p">())</span>
        <span class="p">)</span>
    <span class="p">).</span><span class="n">start</span><span class="p">().</span><span class="n">awaitTermination</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="n">appName</span><span class="p">(</span><span class="s">"RealEstateConsumer"</span><span class="p">).</span><span class="n">config</span><span class="p">(</span>
<span class="s">"spark.cassandra.connection.host"</span><span class="p">,</span> <span class="s">"cassandra"</span>
<span class="p">).</span><span class="n">config</span><span class="p">(</span>
<span class="s">"spark.jars.packages"</span><span class="p">,</span>
<span class="s">"com.datastax.spark:spark-cassandra-connector_2.12:3.4.1,org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0"</span>
<span class="p">).</span><span class="n">getOrCreate</span><span class="p">()</span>

    <span class="n">session</span> <span class="o">=</span> <span class="n">get_cassandra_session</span><span class="p">()</span>
    <span class="n">setup_cassandra</span><span class="p">(</span><span class="n">session</span><span class="p">)</span>
    <span class="n">define_kafka_to_cassandra_flow</span><span class="p">(</span><span class="n">spark</span><span class="p">)</span>

<span class="k">if</span> <span class="o">**</span><span class="n">name</span><span class="o">**</span> <span class="o">==</span> <span class="s">"**main**"</span><span class="p">:</span>
<span class="n">main</span><span class="p">()</span></code></pre></figure>


    <div class="more"><a href="/real-estate-data-engineering/">read more</a></div>
  </article>

  <article>
    <header>
  <h1><a href="/azure-data-management-pipeline/">Azure Data Management Pipeline Application</a></h1><time datetime="2024-04-20T00:00:00+02:00">April 20, 2024</time>
</header>

    <p>In this project, I designed and implemented a robust data management pipeline using Microsoft Azure’s cloud services. Setup of the infrastructure was managed with Terraform. The complete project can be reviewed in my <a href="https://github.com/drjodyannjones/azure-data-management-pipeline" target="\_blank">GitHub repository</a>.</p>

<h3 id="project-overview">Project Overview</h3>

<p>This <strong>Azure Data Management Pipeline</strong> project focuses on the integration of various Azure services to create a scalable and efficient pipeline for data ingestion, processing, and storage. The pipeline facilitates advanced data analysis and is tailored to support enterprises in making agile, informed business decisions. Terraform is utilized to programmatically create, modify, and remove resources on the Microsoft Azure cloud platform.</p>

<h3 id="technologies-employed">Technologies Employed</h3>

<ul>
  <li><strong>Terraform</strong> For programatically managing cloud infrastructure.</li>
  <li><strong>Azure Data Factory:</strong> For orchestrating and automating data flows between various Azure services.</li>
  <li><strong>Azure Databricks:</strong> Utilized for data processing and running big data analytics.</li>
  <li><strong>Azure SQL Database:</strong> Used for storing processed data in a structured format.</li>
  <li><strong>Azure Storage:</strong> Employed for durable, scalable storage of raw data.</li>
</ul>

<h3 id="execution-instructions">Execution Instructions</h3>

<p>To engage with this project, follow these steps:</p>

<ol>
  <li>Clone the repository: <code class="language-plaintext highlighter-rouge">git clone https://github.com/drjodyannjones/azure-data-management-pipeline.git</code></li>
  <li>Set up the Azure services as detailed in the project’s documentation.</li>
  <li>Deploy the Azure Data Factory pipelines and monitor the workflow execution within Azure Portal.</li>
</ol>

<h3 id="sample-code-snippet-maintf">Sample Code Snippet: main.tf</h3>

<p>Here is the main Terraform script that manages the infrastructure:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">terraform</span> <span class="p">{</span>
<span class="n">required_providers</span> <span class="p">{</span>
<span class="n">azurerm</span> <span class="o">=</span> <span class="p">{</span>
<span class="n">source</span> <span class="o">=</span> <span class="s">"hashicorp/azurerm"</span>
<span class="n">version</span> <span class="o">=</span> <span class="s">"~&gt; 3.0.2"</span>
<span class="p">}</span>
<span class="p">}</span>

<span class="n">required_version</span> <span class="o">=</span> <span class="s">"&gt;= 1.1.0"</span>
<span class="p">}</span>

<span class="n">provider</span> <span class="s">"azurerm"</span> <span class="p">{</span>
<span class="n">features</span> <span class="p">{}</span>
<span class="p">}</span>

<span class="n">resource</span> <span class="s">"azurerm_resource_group"</span> <span class="s">"rg"</span> <span class="p">{</span>
<span class="n">name</span> <span class="o">=</span> <span class="n">var</span><span class="p">.</span><span class="n">resource_group_name</span>
<span class="n">location</span> <span class="o">=</span> <span class="n">var</span><span class="p">.</span><span class="n">location</span>
<span class="n">tags</span> <span class="o">=</span> <span class="n">var</span><span class="p">.</span><span class="n">tags</span>
<span class="p">}</span>

<span class="n">module</span> <span class="s">"storage_account"</span> <span class="p">{</span>
<span class="n">source</span> <span class="o">=</span> <span class="s">"./modules/storage_account/storage_account"</span>

<span class="n">resource_group_name</span> <span class="o">=</span> <span class="n">var</span><span class="p">.</span><span class="n">resource_group_name</span>
<span class="n">storage_account_name</span> <span class="o">=</span> <span class="n">var</span><span class="p">.</span><span class="n">storage_account_name</span>
<span class="n">location</span> <span class="o">=</span> <span class="n">var</span><span class="p">.</span><span class="n">location</span>
<span class="n">source_folder_name</span> <span class="o">=</span> <span class="n">var</span><span class="p">.</span><span class="n">source_folder_name</span>
<span class="n">destination_folder_name</span> <span class="o">=</span> <span class="n">var</span><span class="p">.</span><span class="n">destination_folder_name</span>

<span class="n">depends_on</span> <span class="o">=</span> <span class="p">[</span>
<span class="n">azurerm_resource_group</span><span class="p">.</span><span class="n">rg</span>
<span class="p">]</span>

<span class="p">}</span>

<span class="n">module</span> <span class="s">"data_factory"</span> <span class="p">{</span>
<span class="n">source</span> <span class="o">=</span> <span class="s">"./modules/data_factory/data_factory"</span>

<span class="n">df_name</span> <span class="o">=</span> <span class="n">var</span><span class="p">.</span><span class="n">df_name</span>
<span class="n">location</span> <span class="o">=</span> <span class="n">var</span><span class="p">.</span><span class="n">location</span>
<span class="n">resource_group_name</span> <span class="o">=</span> <span class="n">var</span><span class="p">.</span><span class="n">resource_group_name</span>
<span class="n">storage_account_name</span> <span class="o">=</span> <span class="n">var</span><span class="p">.</span><span class="n">storage_account_name</span>

<span class="n">depends_on</span> <span class="o">=</span> <span class="p">[</span>
<span class="n">module</span><span class="p">.</span><span class="n">storage_account</span>
<span class="p">]</span>
<span class="p">}</span></code></pre></figure>


    <div class="more"><a href="/azure-data-management-pipeline/">read more</a></div>
  </article>








<footer>
  <div>Made with <b style="color: #f45;">&lt;3</b></div>
  <nav><a href="mailto:drjodyannjones@gmail.com" ><svg aria-label="Mail" class="icon"><use xlink:href="/assets/fontawesome/icons.svg#envelope"></use></svg></a><a href="https://github.com/drjodyannjones" ><svg aria-label="Github" class="icon"><use xlink:href="/assets/fontawesome/icons.svg#github"></use></svg></a><a href="/feed.xml" ><svg aria-label="Subscribe" class="icon"><use xlink:href="/assets/fontawesome/icons.svg#rss"></use></svg></a></nav>

</footer>


</html>
